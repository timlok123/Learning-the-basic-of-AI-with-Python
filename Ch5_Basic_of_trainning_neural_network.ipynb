{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNScPjEpRi7qBECdVwG+I07",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timlok123/Learning-the-basic-of-AI-with-Python/blob/main/Ch5_Basic_of_trainning_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ch5-Basic of trainning neural network"
      ],
      "metadata": {
        "id": "wvGCns8CTwOv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C_P5zybSTiz5"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following of the notebook, we are going to build a simple neural network with 1-3-1 structure. The layer refers to the connection in between the node.\n",
        "\n",
        "(add the choice of activation function, loss function, optimization methods and batch here)\n",
        "(The tasks of the neural network)"
      ],
      "metadata": {
        "id": "wrFfnZAFkohD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output layer\n",
        "\n",
        "(Add the explantion to the backward propagation of the output layer here)"
      ],
      "metadata": {
        "id": "Gm_lgPQfo4Uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Outputlayer:\n",
        "\n",
        "    def __init__(self, m, n):\n",
        "        WIDTH_CONST = 0.01  # the initial weigh is better to be in this order of magnitude\n",
        "\n",
        "        self.w2 = WIDTH_CONST * np.random.rand(m,n)\n",
        "        self.b = WIDTH_CONST * np.random.rand(n)\n",
        "\n",
        "    def forward(self,y1):\n",
        "      self.y1 = y1\n",
        "\n",
        "      # u = YW + b\n",
        "      u2 = np.dot(y1, self.w2) + self.b2\n",
        "      self.y2 = u2\n",
        "\n",
        "    def backward(self, t):\n",
        "      delta2 = self.y2 - t\n",
        "\n",
        "      self.grad_w2 = np.dot(self.y1.T, delta2)\n",
        "      self.grad_b = np.sum(delta2, axis=0)\n",
        "\n",
        "      self.grad_y1 = np.dot(delta2, self.w2.T)\n",
        "\n",
        "    def update(self,eta):\n",
        "      self.w2 -= eta * self.grad_w2\n",
        "      self.b -= eta * self.grad_b\n"
      ],
      "metadata": {
        "id": "PhK06ht1nh2U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Middle layer\n",
        "\n",
        "- Activation function: Sigmoid function\n",
        "\n",
        "\n",
        "(Explain why does the activation function looks like this)"
      ],
      "metadata": {
        "id": "mJFvA2d-qrzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Middlelayer:\n",
        "\n",
        "    def __init__(self, m, n):\n",
        "        WIDTH_CONST = 0.01  # the initial weigh is better to be in this order of magnitude\n",
        "\n",
        "        self.w = WIDTH_CONST * np.random.rand(m,n)\n",
        "        self.b = WIDTH_CONST * np.random.rand(n)\n",
        "\n",
        "    def forward(self,x):\n",
        "      self.x = x\n",
        "\n",
        "      # u = YW + b\n",
        "      u = np.dot(x, self.w) + self.b\n",
        "      self.y1 = 1/(1 + np.exp(-u))\n",
        "\n",
        "    def backward(self, grad_y1):\n",
        "      delta1 = grad_y1 * (1 - self.y1) * self.y1\n",
        "\n",
        "      self.grad_w = np.dot(self.x.T, delta1)\n",
        "      self.grad_b = np.sum(delta1, axis=0)\n",
        "\n",
        "    def update(self,eta):\n",
        "      self.w2 -= eta * self.grad_w2\n",
        "      self.b -= eta * self.grad_b"
      ],
      "metadata": {
        "id": "KMqO_3lqq0L_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct the neural network"
      ],
      "metadata": {
        "id": "Oa_OniETsDDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data preparation\n",
        "\n",
        "input_data = np.arange(0, np.pi, 0.1)\n",
        "correct_data = np.sin(np.arange(0, np.pi, 0.1))\n",
        "input_data_normalized = (input_data - np.pi)/np.pi  # To control the data to be lying between -1 to 1\n",
        "no_of_data = len(input_data)\n",
        "\n",
        "# Hyperparameters tuning\n",
        "\n",
        "n_in = 1\n",
        "n_mid = 3\n",
        "n_out = 1\n",
        "\n",
        "eta = 0.1\n",
        "epoch = 2000\n",
        "\n",
        "# Initialize the model\n",
        "\n",
        "middle_layer = Middlelayer(n_in, n_mid)\n",
        "output_layer = Middlelayer(n_mid, n_out)\n",
        "\n",
        "# Training process\n",
        "\n",
        "for i in range(epoch):\n",
        "\n",
        "    # Shuffle the index randomly\n",
        "    random_index = np.arange(0,no_of_data)\n",
        "    np.random.shuffle(random_index)\n",
        "\n",
        "    for idx in random_index:\n",
        "\n",
        "      input_x = input_data[idx]\n",
        "      label_t = correct_data[idx]\n",
        "\n",
        "      # Forward propagation\n",
        "      middle_layer.forward(input_x.reshape(1,1))\n",
        "      output_layer.forward(middle_layer.y1)\n",
        "\n",
        "      # Backward propagation\n",
        "      # TODO: fill it out\n",
        "\n",
        "      # Update eta\n",
        "      # TODO: fill it out\n",
        "\n"
      ],
      "metadata": {
        "id": "Ifp7SwRrsKVi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demonstrate the result after training - Put the corresponding input to the model & plot the output\n",
        "# TODO: fill it out"
      ],
      "metadata": {
        "id": "ehE--Rquuoqu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(random_index)\n",
        "print(random_index[3:4])"
      ],
      "metadata": {
        "id": "lY9kVOYvuuJv",
        "outputId": "7f622ac9-ef73-4b41-e552-63f4509c925e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1 20 15 26 31 12 25  6 19  7  5  2 21 14 29 23 11 30 16 13  3 22  8 28\n",
            " 17 24  9  4  0 18 27 10]\n",
            "[26]\n"
          ]
        }
      ]
    }
  ]
}