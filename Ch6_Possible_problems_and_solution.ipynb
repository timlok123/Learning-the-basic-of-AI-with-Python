{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvGCns8CTwOv"
      },
      "source": [
        "# Ch6 - Possible problem in AI training and Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "C_P5zybSTiz5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(List the possible problems & solution encountered during training AI network)"
      ],
      "metadata": {
        "id": "PtMnD1cirZps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural network training"
      ],
      "metadata": {
        "id": "N19bdilotIbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction"
      ],
      "metadata": {
        "id": "GSzafuwbsswx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following of the notebook, we are using the *Iris flower dataset* for training.\n",
        "(Explanation on the data, the components of data, no of data)"
      ],
      "metadata": {
        "id": "gPOWd7jvrqt0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(The structure of the AI model, activation function & output layer function in between, optimization methods and loss function, batch size, test case,  )"
      ],
      "metadata": {
        "id": "-Qz9yUFrsGG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preparation"
      ],
      "metadata": {
        "id": "SnXijPwNs1zU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are the steps of data preparation,\n",
        "\n",
        "1. Load the data from *sklearn* module\n",
        "2. Normalization\n",
        "3. Convert the label for training (Understand why do we need to do this)\n",
        "4. Split the train and test case"
      ],
      "metadata": {
        "id": "rO9aIlfztqo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "iris_data = datasets.load_iris()\n",
        "input_data = iris_data.data\n",
        "correct = iris_data.target\n",
        "\n",
        "no_of_data = len(correct)"
      ],
      "metadata": {
        "id": "MZ3vgKrMs-L-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first 10 data & take a look of the data\n",
        "print(input_data[:10,])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaWjDCTHvP0W",
        "outputId": "b16a574f-df32-47ad-ef95-53ab662ece78"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "mean_col = np.mean(input_data,axis=0)\n",
        "std_col = np.std(input_data,axis=0)\n",
        "normalized_data = (input_data - mean_col)/(std_col)"
      ],
      "metadata": {
        "id": "lC40MQKwvLO2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Turn the `correct` to one-hot labelling (Add the graph of one-hot labelling scheme & why do we need to turn it to one-hot)"
      ],
      "metadata": {
        "id": "plCK2MM6waD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn the `correct` to one-hot labelling\n",
        "correct_data = np.zeros((no_of_data,3),dtype=int)\n",
        "\n",
        "# TODO: Figure out a way to make use the vectorization\n",
        "for i in range(no_of_data):\n",
        "    correct_data[i][correct[i]] = 1\n"
      ],
      "metadata": {
        "id": "HxVI3Zt_wGDw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data to test & learn case\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "input_train, input_test, correct_train, correct_test = train_test_split(\n",
        "    normalized_data,\n",
        "    correct_data,\n",
        "    test_size=no_of_data//2\n",
        ")\n",
        "\n",
        "n_train = no_of_data//2"
      ],
      "metadata": {
        "id": "_bQF7hsezN8e"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Network structure"
      ],
      "metadata": {
        "id": "paMrEpoas4OD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Define the hyperparameters & initial vaules for the network\n",
        "2. Define the layer structure as object\n",
        "3. Forward and back propagation definition\n"
      ],
      "metadata": {
        "id": "jqIfjwqz0sDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nework neuron\n",
        "n_in = 4 # since we get 4 features for each x\n",
        "n_mid = 25\n",
        "n_out = 3\n",
        "\n",
        "eta = 0.01      # learning rate for SGD\n",
        "epoch = 1000    # No of training times\n",
        "batch_size = 8\n",
        "\n",
        "interval = 100  # Showing the training accuracy every (interval) times"
      ],
      "metadata": {
        "id": "VYxMBcd9rp0b"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(ReLu definition, Softmax expression)"
      ],
      "metadata": {
        "id": "SBGfQw5-3n0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the layer structure & methods\n",
        "\n",
        "\n",
        "# Define the common properities in BaseLayer\n",
        "class BaseLayer:\n",
        "  def __init__(self,n_upper,n, wb_width = 0.1): # n_upper - no of neurons in last layer, n - no of neurons\n",
        "    self.w = wb_width * np.random.randn(n_upper, n)\n",
        "    self.b = wb_width * np.random.randn(n)\n",
        "\n",
        "  def update(self,eta):\n",
        "    self.w -= eta * self.grad_w\n",
        "    self.b -= eta * self.grad_b\n",
        "\n",
        "# Middle layer\n",
        "class MiddleLayer(BaseLayer):\n",
        "  def forward(self, x):\n",
        "    self.x = x\n",
        "    self.u = np.dot(x, self.w) + self.b\n",
        "    self.y = np.where(self.u<=0, 0, self.u) # ReLu activation function ]\n",
        "\n",
        "  def backward(self,grad_y):\n",
        "    delta = grad_y * np.where(self.u>0, 1, 0) # grad_y * derivative of ReLu\n",
        "\n",
        "    self.grad_w = np.dot(self.x.T, delta)\n",
        "    self.grad_b = np.sum(delta, axis=0)\n",
        "\n",
        "    self.grad_x = np.dot(delta, self.w.T)\n",
        "\n",
        "# Output layer\n",
        "class OutputLayer(BaseLayer):\n",
        "  def forward(self,x):\n",
        "    self.x = x\n",
        "    self.u = np.dot(x,self.w) + self.b\n",
        "    self.y = np.exp(self.u)/(np.sum(self.u,axis=1,keepdims=True))\n",
        "\n",
        "  def backward(self,t):\n",
        "    delta = self.y - t\n",
        "\n",
        "    self.grad_w = np.dot(self.x.T, delta)\n",
        "    self.grad_b = np.sum(delta, axis=0)\n",
        "\n",
        "    self.grad_x = np.dot(delta, self.w.T)\n"
      ],
      "metadata": {
        "id": "JSW2pfrz2H47"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural network structure\n",
        "\n",
        "middle_layer_1 = MiddleLayer(n_in, n_mid)\n",
        "middle_layer_2 = MiddleLayer(n_mid, n_mid)\n",
        "output_layer = OutputLayer(n_mid,n_out)"
      ],
      "metadata": {
        "id": "CV4x38gc87EY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the forward, backward propagation, update_weight of different layer in the function\n",
        "\n",
        "def forward_propagation(x):\n",
        "  middle_layer_1.forward(x)\n",
        "  middle_layer_2.forward(middle_layer_1.y)\n",
        "  output_layer.forward(middle_layer_2.y)\n",
        "\n",
        "def backward_propagation(t):\n",
        "  output_layer.backward(t)\n",
        "  middle_layer_2.backward(output_layer.grad_x)\n",
        "  middle_layer_1.backward(middle_layer_2.grad_x)\n",
        "\n",
        "def update_wb(eta):\n",
        "  middle_layer_1.update(eta)\n",
        "  middle_layer_2.update(eta)\n",
        "  output_layer.update(eta)\n",
        "\n",
        "def get_error(t, batch_size):\n",
        "  # Basically calcaluating the cost function value and normalize with the batch size\n",
        "  # add 1e-7 to avoid ln(0)\n",
        "  return -np.sum(-t * np.log(output_layer.y + 1e-7))/batch_size\n",
        "\n"
      ],
      "metadata": {
        "id": "U9Fze_fRqulj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training procedures"
      ],
      "metadata": {
        "id": "DYbvkgKNs_7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_error = []\n",
        "\n",
        "test_error = []\n",
        "\n",
        "no_of_batch = n_train // batch_size\n",
        "\n",
        "for i in range(epoch):\n",
        "\n",
        "  # Record the error on training & test case in every training\n",
        "  forward_propagation(input_train)\n",
        "  train_error.append(get_error(correct_train, batch_size))\n",
        "\n",
        "  forward_propagation(input_test)\n",
        "  test_error.append(get_error(correct_test, batch_size))\n",
        "\n",
        "  # Shuffle the data & prepare the index\n",
        "  index_random = np.arange(n_train)\n",
        "  np.random.shuffle(index_random)\n",
        "\n",
        "  for j in range(no_of_batch):\n",
        "\n",
        "    mini_batch_index = index_random[j*batch_size:(j+1)*batch_size]\n",
        "    x = input_train[mini_batch_index, :]\n",
        "    t = correct_train[mini_batch_index, :]\n",
        "\n",
        "    forward_propagation(x)\n",
        "    backward_propagation(t)\n",
        "    update_wb(eta)"
      ],
      "metadata": {
        "id": "3JwKjFjhrY9u",
        "outputId": "fcf5e76d-cc50-4f04-e05b-e33b61aa0989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1f8081bbb656>:21: RuntimeWarning: invalid value encountered in log\n",
            "  return -np.sum(-t * np.log(output_layer.y + 1e-7))/batch_size\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MiddleLayer' object has no attribute 'b_'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-d07ed4419c63>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mbackward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mupdate_wb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-1f8081bbb656>\u001b[0m in \u001b[0;36mupdate_wb\u001b[0;34m(eta)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupdate_wb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mmiddle_layer_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0mmiddle_layer_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0moutput_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-12302679dd79>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, eta)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_\u001b[0m\u001b[0;34m-=\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Middle layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'MiddleLayer' object has no attribute 'b_'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}